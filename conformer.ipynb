{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7589aabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np \n",
    "sys.path.append('./')\n",
    "\n",
    "from encoder import ConformerEncoder, ConformerBlock\n",
    "\n",
    "import librosa\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde96814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset setup\n",
    "class TimbreDataset(Dataset):\n",
    "    def __init__(self, root_dir, instrument_to_label, sample_rate=22050, duration_ms=500, n_mels=128):\n",
    "        self.samples = []\n",
    "        self.labels = []\n",
    "        self.sr = sample_rate\n",
    "        self.clip_len = int(sample_rate * duration_ms / 1000)\n",
    "        self.n_mels = n_mels\n",
    "        self.instrument_to_label = instrument_to_label\n",
    "         \n",
    "        # preprocess\n",
    "        for instrument, label in instrument_to_label.items():\n",
    "            inst_dir = os.path.join(root_dir, instrument)\n",
    "            if not os.path.isdir(inst_dir):\n",
    "                continue  # Skip if not a valid directory\n",
    "            for file in os.listdir(inst_dir):\n",
    "                if file.endswith('.mp3'):\n",
    "                    file_path = os.path.join(inst_dir, file)\n",
    "                    try:\n",
    "                        # Attempt to load the file\n",
    "                        y, _ = librosa.load(file_path, sr=self.sr)\n",
    "                        y_trim, _ = librosa.effects.trim(y, top_db=30)\n",
    "                        clip = y_trim[:self.clip_len]\n",
    "                        if len(clip) < self.clip_len:\n",
    "                            clip = np.pad(clip, (0, self.clip_len - len(clip)))\n",
    "                        mel = librosa.feature.melspectrogram(y=clip, sr=self.sr, n_mels=self.n_mels)\n",
    "                        log_mel = librosa.power_to_db(mel, ref=np.max)\n",
    "                        \n",
    "                        # Ensure the time axis is fixed length\n",
    "                        target_frames = 22  # whatever size you want\n",
    "                        if log_mel.shape[1] < target_frames:\n",
    "                            pad_width = target_frames - log_mel.shape[1]\n",
    "                            log_mel = np.pad(log_mel, ((0, 0), (0, pad_width)), mode='constant')\n",
    "                        else:\n",
    "                            log_mel = log_mel[:, :target_frames]\n",
    "\n",
    "                        self.samples.append(file_path)\n",
    "                        self.labels.append(label)\n",
    "                    except Exception as e:\n",
    "                        # Log the issue and skip the corrupted file\n",
    "                        print(f\"[Error] Skipping {file_path}: {e}\")\n",
    "                        continue  # Skip this file and continue with the rest\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.samples[idx]\n",
    "        label = self.labels[idx]\n",
    "        try:\n",
    "            y, _ = librosa.load(file_path, sr=self.sr)\n",
    "            y_trim, _ = librosa.effects.trim(y, top_db=30)\n",
    "            clip = y_trim[:self.clip_len]\n",
    "            if len(clip) < self.clip_len:\n",
    "                clip = np.pad(clip, (0, self.clip_len - len(clip)))\n",
    "            mel = librosa.feature.melspectrogram(y=clip, sr=self.sr, n_mels=self.n_mels)\n",
    "            log_mel = librosa.power_to_db(mel, ref=np.max)\n",
    "            \n",
    "            # Ensure the time axis is fixed length\n",
    "            target_frames = 22  # whatever size you want\n",
    "            if log_mel.shape[1] < target_frames:\n",
    "                pad_width = target_frames - log_mel.shape[1]\n",
    "                log_mel = np.pad(log_mel, ((0, 0), (0, pad_width)), mode='constant')\n",
    "            else:\n",
    "                log_mel = log_mel[:, :target_frames]\n",
    "\n",
    "            return torch.tensor(log_mel, dtype=torch.float32).unsqueeze(0), torch.tensor(label, dtype=torch.long)\n",
    "        except Exception as e:\n",
    "            print(f\"[Error] Skipping {file_path}: {e}\")\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e35e316f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "class ConformerClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=128, num_classes=58, num_blocks=4, hidden_dim=144, num_heads=4, dropout=0.1):\n",
    "        super(ConformerClassifier, self).__init__()\n",
    "        self.input_proj = nn.Conv1d(input_dim, hidden_dim, kernel_size=1)\n",
    "        self.conformer_blocks = nn.Sequential(*[\n",
    "            ConformerBlock(\n",
    "                encoder_dim=hidden_dim,\n",
    "                num_attention_heads=num_heads,\n",
    "                feed_forward_expansion_factor=4,\n",
    "                conv_expansion_factor=2,\n",
    "                feed_forward_dropout_p=dropout,\n",
    "                attention_dropout_p=dropout,\n",
    "                conv_dropout_p=dropout,\n",
    "                conv_kernel_size=31,\n",
    "                half_step_residual=True\n",
    "            ) for _ in range(num_blocks)\n",
    "        ])\n",
    "        self.pooling = nn.AdaptiveAvgPool1d(1)\n",
    "        self.classifier = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.squeeze(1)  # From (B, 1, F, T) to (B, F, T)\n",
    "        x = self.input_proj(x)  # (B, hidden_dim, T)\n",
    "        x = x.transpose(1, 2)   # (B, T, hidden_dim) for conformer\n",
    "        x = self.conformer_blocks(x)\n",
    "        x = x.transpose(1, 2)   # Back to (B, hidden_dim, T)\n",
    "        x = self.pooling(x).squeeze(-1)  # (B, hidden_dim)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51e56d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train sample 0: Label = 1\n",
      "Train sample 1: Label = 2\n",
      "Train sample 2: Label = 1\n",
      "Train sample 3: Label = 1\n",
      "Train sample 4: Label = 2\n",
      "Validation sample 0: Label = 1\n",
      "Validation sample 1: Label = 0\n",
      "Validation sample 2: Label = 2\n",
      "Validation sample 3: Label = 0\n",
      "Validation sample 4: Label = 1\n",
      "Test sample 0: Label = 2\n",
      "Test sample 1: Label = 2\n",
      "Test sample 2: Label = 1\n",
      "Test sample 3: Label = 2\n",
      "Test sample 4: Label = 2\n"
     ]
    }
   ],
   "source": [
    "# Class mapping\n",
    "classes = [\"cello\", \"viola\", \"violin\"] \n",
    "# classes = ['violin', 'viola', 'cello', 'double bass', 'clarinet', 'bass clarinet', 'saxophone', 'flute',\n",
    "#            'oboe', 'bassoon', 'contrabassoon', 'cor anglais', 'french horn', 'trombone', 'trumpet', 'tuba',\n",
    "#             'guitar', 'mandolin', 'banjo', 'percussion']\n",
    "instrument_to_label = {name: idx for idx, name in enumerate(classes)}\n",
    "\n",
    "# Splitting\n",
    "dataset = TimbreDataset(\"data/all-samples\", instrument_to_label)\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train_ds, val_ds, test_ds = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_ds, batch_size=16, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b51ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device + model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ConformerClassifier(input_dim=128, num_classes=len(classes)).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(5):  # Fewer epochs for initial testing\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(x_batch)\n",
    "        loss = criterion(preds, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# Evaluation on validation set\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x_batch, y_batch in val_loader:\n",
    "        try:\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            preds = model(x_batch)\n",
    "            pred_labels = torch.argmax(preds, dim=1)\n",
    "            all_preds.extend(pred_labels.cpu().numpy())\n",
    "            all_targets.extend(y_batch.cpu().numpy())\n",
    "        except Exception as e:\n",
    "            print(f\"[Skipping batch due to error]: {e}\")\n",
    "            continue\n",
    "\n",
    "if len(all_targets) > 0 and len(all_preds) > 0:\n",
    "    precision = precision_score(all_targets, all_preds, average='macro', zero_division=0)\n",
    "    recall = recall_score(all_targets, all_preds, average='macro', zero_division=0)\n",
    "    f1 = f1_score(all_targets, all_preds, average='macro', zero_division=0)\n",
    "\n",
    "    print(f\"\\nPrecision: {precision:.3f}, Recall: {recall:.3f}, F1 Score: {f1:.3f}\")\n",
    "\n",
    "    # Confusion Matrix Plot\n",
    "    cm = confusion_matrix(all_targets, all_preds)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=classes, yticklabels=classes, cmap=\"magma\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"[Warning] No predictions made — confusion matrix cannot be computed.\")\n",
    "\n",
    "# precision = precision_score(all_targets, all_preds, average='macro', zero_division=0)\n",
    "# recall = recall_score(all_targets, all_preds, average='macro', zero_division=0)\n",
    "# f1 = f1_score(all_targets, all_preds, average='macro', zero_division=0)\n",
    "\n",
    "# print(f\"\\nPrecision: {precision:.3f}, Recall: {recall:.3f}, F1 Score: {f1:.3f}\")\n",
    "\n",
    "# # Confusion Matrix Plot\n",
    "# cm = confusion_matrix(all_targets, all_preds)\n",
    "# plt.figure(figsize=(6, 5))\n",
    "# sns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=classes, yticklabels=classes, cmap=\"magma\")\n",
    "# plt.xlabel(\"Predicted\")\n",
    "# plt.ylabel(\"True\")\n",
    "# plt.title(\"Confusion Matrix\")\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csci1470",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
